<div align="center">

# âœ‹ Hand-Raise Detection App  
**Android | Jetpack Compose | CameraX | ML Kit | MVVM | Text-to-Speech**

---

![Android](https://img.shields.io/badge/Platform-Android-3DDC84?logo=android&logoColor=white)
![Kotlin](https://img.shields.io/badge/Kotlin-1.9-purple?logo=kotlin)
![Jetpack Compose](https://img.shields.io/badge/UI-Jetpack%20Compose-4285F4?logo=jetpackcompose&logoColor=white)
![ML Kit](https://img.shields.io/badge/ML%20Kit-Pose%20Detection-orange?logo=google)
![CameraX](https://img.shields.io/badge/Camera-CameraX-lightblue)
![Architecture](https://img.shields.io/badge/Architecture-MVVM-blueviolet)
![License](https://img.shields.io/badge/License-MIT-green)

---

</div>

## ğŸ“Œ Overview

This Android application detects when a user raises their hand above shoulder level using **Google ML Kit Pose Detection** and responds using **Text-to-Speech**.

Once a hand is detected, the app speaks:

> **â€œHand detected, how can I help you?â€**

The UI is built entirely using **Jetpack Compose**, and the project follows a clean **MVVM architecture** using UI state and one-time events.

---

## ğŸš€ Features

- ğŸ“· Live camera feed with **CameraX**
- ğŸ§  Hand-raise gesture using **ML Kit Pose Detection**
- âœ‹ Detects left or right hand above shoulder level
- ğŸ”Š Voice feedback using device Text-to-Speech
- ğŸ§© MVVM with state + event-driven communication
- ğŸ¨ Pure Jetpack Compose UI (no XML)

---

## ğŸ› Architecture

The app follows an MVVM structure:



View (Compose UI) â† observes â€” ViewModel â€” exposes â†’ State + One-Time Events


| Layer | Role |
|-------|------|
| **View (CameraScreen)** | Displays camera preview, UI text, and reacts to events (like speaking). |
| **ViewModel** | Processes frames, runs ML logic, detects gestures, and fires `Speak` events. |
| **Model/Data** | Pose detection result and UI state values. |

UI contains **no business logic** â€” everything is decided in the ViewModel.

---

## ğŸ§  Detection Logic

A hand is considered raised when:

wrist.position.y < shoulder.position.y


The UI contains zero business logic â€” it only reacts to changes.

ğŸ§  Gesture Logic

A hand is considered raised if:

```kotlin
wrist.position.y < shoulder.position.y
```


Since ML Kit coordinates treat lower y-values as higher on screen, this comparison accurately detects a raised hand.

Either hand can trigger the response.

## ğŸ§° Tech Stack

| Category | Technology |
|----------|------------|
| Language | Kotlin |
| UI | Jetpack Compose |
| Camera | CameraX |
| ML | ML Kit Pose Detection (Accurate Model) |
| Architecture | MVVM |
| Speech | Android Text-to-Speech |


Android physical device (recommended)

Android API Level 24+

Camera permission granted at runtime

ğŸš« Pose detection may not work on emulators.

ğŸ‘¤ Author

Aditya Raj
Made with â¤ï¸ and Kotlin.

